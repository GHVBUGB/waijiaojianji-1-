"""
è…¾è®¯äº‘ä¸‡è±¡è§†é¢‘äººåƒæŠ å›¾æœåŠ¡ - è§†é¢‘èƒŒæ™¯ç§»é™¤
ä½¿ç”¨è…¾è®¯äº‘æ•°æ®ä¸‡è±¡çš„SegmentVideoBody API
"""

import asyncio
import json
import logging
import os
import tempfile
import time
import base64
from typing import Dict
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
import hashlib
import hmac
import urllib.parse
import urllib3

# ç¦ç”¨SSLè­¦å‘Šï¼ˆç”¨äºè§£å†³ç½‘ç»œç¯å¢ƒSSLé—®é¢˜ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from app.config.settings import settings
from app.services.robust_cos_uploader import RobustCOSUploader

logger = logging.getLogger(__name__)

class TencentVideoService:
    """è…¾è®¯äº‘ä¸‡è±¡è§†é¢‘äººåƒæŠ å›¾æœåŠ¡"""
    
    def __init__(self):
        self.secret_id = getattr(settings, 'TENCENT_SECRET_ID', None)
        self.secret_key = getattr(settings, 'TENCENT_SECRET_KEY', None)
        self.region = getattr(settings, 'TENCENT_REGION', 'ap-singapore')
        
        # è…¾è®¯äº‘ä¸‡è±¡é…ç½®
        self.bucket_name = getattr(settings, 'TENCENT_COS_BUCKET', None)
        self.app_id = getattr(settings, 'TENCENT_APP_ID', None)
        
        # æ€§èƒ½ä¼˜åŒ–é…ç½®
        self.frame_skip = getattr(settings, 'TENCENT_FRAME_SKIP', 5)
        self.motion_detection = getattr(settings, 'TENCENT_MOTION_DETECTION', True)
        self.max_concurrent_jobs = getattr(settings, 'MAX_CONCURRENT_JOBS', 3)
        self.chunk_size = getattr(settings, 'UPLOAD_CHUNK_SIZE', 8 * 1024 * 1024)
        
        # åˆå§‹åŒ–å¥å£®çš„COSä¸Šä¼ å™¨
        if self.secret_id and self.secret_key and self.bucket_name:
            self.cos_uploader = RobustCOSUploader(
                self.secret_id, 
                self.secret_key, 
                self.region, 
                self.bucket_name
            )
        else:
            self.cos_uploader = None
            logger.warning("è…¾è®¯äº‘COSä¸Šä¼ å™¨åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘å¿…è¦é…ç½®")
        
        if not self.secret_id or not self.secret_key:
            logger.warning("è…¾è®¯äº‘è§†é¢‘æœåŠ¡æœªé…ç½®è®¿é—®å¯†é’¥")
        if not self.bucket_name:
            logger.warning("è…¾è®¯äº‘ä¸‡è±¡æœåŠ¡éœ€è¦é…ç½®COSå­˜å‚¨æ¡¶")
    
    def _open_ai_bucket(self) -> bool:
        """è°ƒç”¨ä¸‡è±¡ API: å¼€é€š AI å†…å®¹è¯†åˆ«ï¼ˆå¼‚æ­¥ï¼‰æœåŠ¡å¹¶ç”Ÿæˆé˜Ÿåˆ—ã€‚
        POST https://<Bucket-APPID>.ci.<Region>.myqcloud.com/ai_bucket
        è¯·æ±‚ä½“ä¸ºç©ºã€‚
        """
        ci_host = f"{self.bucket_name}.ci.{self.region}.myqcloud.com"
        url = f"https://{ci_host}/ai_bucket"
        headers = {
            'Authorization': self._generate_authorization("POST", "/ai_bucket"),
            'Host': ci_host,
            'Content-Type': 'application/xml',
            'Date': datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        }
        try:
            logger.info("ğŸ§© å°è¯•å¼€é€š AI å†…å®¹è¯†åˆ«æœåŠ¡ (POST /ai_bucket)")
            response = requests.post(url, data=b"", headers=headers, timeout=30, verify=True)
            logger.info(f"ğŸ§© å¼€é€šAIæœåŠ¡å“åº”: {response.status_code}")
            if response.status_code == 200:
                logger.info(f"ğŸ§© å¼€é€šAIæœåŠ¡ç»“æœ: {response.text}")
                return True
            logger.error(f"ğŸ§© å¼€é€šAIæœåŠ¡å¤±è´¥: {response.status_code} - {response.text}")
            return False
        except Exception as e:
            logger.error(f"ğŸ§© å¼€é€šAIæœåŠ¡å¼‚å¸¸: {str(e)}")
            return False

    def _generate_authorization(self, method: str, uri: str, body: str = "", headers: dict = None) -> str:
        """ç”Ÿæˆè…¾è®¯äº‘ä¸‡è±¡APIæˆæƒç­¾å"""
        if headers is None:
            headers = {}
        
        # æ—¶é—´æˆ³
        now = int(time.time())
        expired = now + 3600  # 1å°æ—¶åè¿‡æœŸ
        
        # ç”Ÿæˆ KeyTime
        key_time = f"{now};{expired}"
        
        # ç”Ÿæˆ SignKey
        sign_key = hmac.new(
            self.secret_key.encode('utf-8'),
            key_time.encode('utf-8'),
            hashlib.sha1
        ).hexdigest()
        
        # ç”Ÿæˆ HttpString - ä¸‡è±¡APIæ ¼å¼ï¼Œéœ€è¦åŒ…å«hostå¤´
        http_string = f"{method.lower()}\n{uri}\n\nhost={self.bucket_name}.ci.{self.region}.myqcloud.com\n"
        
        # ç”Ÿæˆ StringToSign
        string_to_sign = f"sha1\n{key_time}\n{hashlib.sha1(http_string.encode('utf-8')).hexdigest()}\n"
        
        # ç”Ÿæˆ Signature
        signature = hmac.new(
            sign_key.encode('utf-8'),
            string_to_sign.encode('utf-8'),
            hashlib.sha1
        ).hexdigest()
        
        # ç”Ÿæˆ Authorization - ä¸‡è±¡APIæ ¼å¼ï¼Œéœ€è¦åŒ…å«hoståœ¨header-listä¸­
        authorization = (
            f"q-sign-algorithm=sha1&"
            f"q-ak={self.secret_id}&"
            f"q-sign-time={key_time}&"
            f"q-key-time={key_time}&"
            f"q-header-list=host&"
            f"q-url-param-list=&"
            f"q-signature={signature}"
        )
        
        return authorization
    
    def _cos_hosts(self) -> list:
        """æŒ‰ä¼˜å…ˆçº§è¿”å›å¯ç”¨çš„ COS åŸŸåå€™é€‰"""
        use_accelerate = os.getenv("TENCENT_COS_ACCELERATE", "false").lower() == "true"
        hosts = []
        
        # å…¨çƒåŠ é€Ÿï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if use_accelerate:
            hosts.append(f"{self.bucket_name}.cos.accelerate.myqcloud.com")
        
        # åœ°åŸŸåŸŸå
        hosts.append(f"{self.bucket_name}.cos.{self.region}.myqcloud.com")
        
        # å¤‡ç”¨åŸŸå
        hosts.append(f"{self.bucket_name}.cos.{self.region}.tencentcos.cn")
        
        return hosts
    
    async def _upload_to_cos(self, local_path: str, object_key: str):
        """ä½¿ç”¨å¥å£®çš„COSä¸Šä¼ å™¨ä¸Šä¼ æ–‡ä»¶"""
        logger.info(f"ğŸ“¤ ä½¿ç”¨å¥å£®ä¸Šä¼ å™¨ä¸Šä¼ æ–‡ä»¶: {local_path} -> {object_key}")
        
        if not self.cos_uploader:
            raise Exception("COSä¸Šä¼ å™¨æœªåˆå§‹åŒ–")
        
        success = await self.cos_uploader.upload_file(local_path, object_key)
        if not success:
            raise Exception("æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
    
    async def _download_from_cos(self, object_key: str, local_path: str):
        """ä½¿ç”¨å¥å£®çš„COSä¸‹è½½å™¨ä¸‹è½½æ–‡ä»¶"""
        logger.info(f"ğŸ“¥ ä½¿ç”¨å¥å£®ä¸‹è½½å™¨ä¸‹è½½æ–‡ä»¶: {object_key} -> {local_path}")
        
        if not self.cos_uploader:
            raise Exception("COSä¸Šä¼ å™¨æœªåˆå§‹åŒ–")
        
        success = await self.cos_uploader.download_file(object_key, local_path)
        if not success:
            raise Exception("æ–‡ä»¶ä¸‹è½½å¤±è´¥")
    
    def _activate_ai_queue(self, queue_id: str) -> bool:
        """å°† AI é˜Ÿåˆ—ç½®ä¸º Active çŠ¶æ€ (PUT /ai_queue/<queueId>)"""
        if not queue_id:
            return False
        ci_host = f"{self.bucket_name}.ci.{self.region}.myqcloud.com"
        url = f"https://{ci_host}/ai_queue/{queue_id}"
        headers = {
            'Authorization': self._generate_authorization("PUT", f"/ai_queue/{queue_id}"),
            'Host': ci_host,
            'Content-Type': 'application/xml',
            'Date': datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        }
        # ç½®ä¸º Activeï¼Œå…³é—­å›è°ƒ
        body_xml = """
<Request>
    <Name>AI-Queue</Name>
    <State>Active</State>
    <NotifyConfig>
        <State>Off</State>
    </NotifyConfig>
</Request>
""".strip()
        try:
            logger.info(f"ğŸ› ï¸ æ¿€æ´»AIé˜Ÿåˆ—: {queue_id}")
            resp = requests.put(url, data=body_xml.encode('utf-8'), headers=headers, timeout=30, verify=True)
            logger.info(f"ğŸ› ï¸ æ¿€æ´»å“åº”: {resp.status_code}")
            return resp.status_code == 200
        except Exception as e:
            logger.error(f"ğŸ› ï¸ æ¿€æ´»AIé˜Ÿåˆ—å¼‚å¸¸: {str(e)}")
            return False

    async def _get_queue_id(self) -> str:
        """è·å–ä¸‡è±¡æœåŠ¡çš„é˜Ÿåˆ—IDï¼ˆä½¿ç”¨ /ai_queueï¼Œä¼˜å…ˆé€‰æ‹© AIProcess é˜Ÿåˆ—ï¼‰"""
        logger.info("ğŸ” è·å–ä¸‡è±¡æœåŠ¡é˜Ÿåˆ—ID")
        
        ci_host = f"{self.bucket_name}.ci.{self.region}.myqcloud.com"
        url = f"https://{ci_host}/ai_queue"
        
        authorization = self._generate_authorization("GET", "/ai_queue")
        headers = {
            'Authorization': authorization,
            'Host': ci_host,
            'Date': datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=30, verify=True)
            logger.info(f"ğŸ“¡ é˜Ÿåˆ—æŸ¥è¯¢å“åº”: {response.status_code}")
            
            if response.status_code != 200:
                logger.warning(f"âš ï¸ é˜Ÿåˆ—æŸ¥è¯¢å¤±è´¥: {response.status_code}")
                return ""

            logger.info(f"ğŸ“„ é˜Ÿåˆ—å“åº”å†…å®¹: {response.text}")
            root = ET.fromstring(response.content)

            ai_queue_id = None
            any_active_queue_id = None

            queue_list = root.find('.//QueueList')
            if queue_list is not None:
                logger.info("ğŸ“‹ æ‰¾åˆ°é˜Ÿåˆ—åˆ—è¡¨")
                for queue in queue_list.findall('Queue'):
                    queue_id_el = queue.find('QueueId')
                    state_el = queue.find('State')
                    name_el = queue.find('Name')
                    queue_type_el = queue.find('QueueType') or queue.find('Category')

                    queue_id = queue_id_el.text if queue_id_el is not None else None
                    state = state_el.text if state_el is not None else 'Unknown'
                    name = name_el.text if name_el is not None else 'Unknown'
                    queue_type = queue_type_el.text if queue_type_el is not None else 'Unknown'

                    logger.info(f"ğŸ“ é˜Ÿåˆ—ä¿¡æ¯: ID={queue_id}, State={state}, Type={queue_type}, Name={name}")

                    if state == 'Paused' and queue_id and (queue_type == 'AIProcess'):
                        # è‡ªåŠ¨å°è¯•æ¿€æ´»
                        self._activate_ai_queue(queue_id)
                        # æ¿€æ´»åä¼˜å…ˆè¿”å›è¯¥é˜Ÿåˆ—
                        ai_queue_id = queue_id
                        break

                    if state == 'Active' and queue_id:
                        # è®°å½•ä»»ä¸€æ´»è·ƒé˜Ÿåˆ—
                        if any_active_queue_id is None:
                            any_active_queue_id = queue_id
                        # ä¼˜å…ˆé€‰æ‹© AIProcess
                        if queue_type == 'AIProcess':
                            ai_queue_id = queue_id
                            break

            if ai_queue_id:
                logger.info(f"âœ… é€‰æ‹© AIProcess é˜Ÿåˆ—: {ai_queue_id}")
                return ai_queue_id

            if any_active_queue_id:
                logger.warning("âš ï¸ æœªæ‰¾åˆ° AIProcess é˜Ÿåˆ—ï¼Œåç»­å°†ä¸ä¼  QueueIdï¼Œé¿å…è¯¯ç”¨ Transcoding é˜Ÿåˆ—")
                return ""

            # æœªæ‰¾åˆ°ä»»ä½•é˜Ÿåˆ—ï¼Œå°è¯•è‡ªåŠ¨å¼€é€š AI æœåŠ¡
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•é˜Ÿåˆ—ï¼Œè‡ªåŠ¨å°è¯•å¼€é€š AI å†…å®¹è¯†åˆ«æœåŠ¡åé‡è¯•æŸ¥è¯¢é˜Ÿåˆ—")
            if self._open_ai_bucket():
                # å¼€é€šåç­‰å¾…å‡ ç§’å†æŸ¥
                time.sleep(3)
                try:
                    response2 = requests.get(url, headers=headers, timeout=30, verify=True)
                    if response2.status_code == 200:
                        root2 = ET.fromstring(response2.content)
                        # å†æ¬¡ä¼˜å…ˆé€‰æ‹© AIProcess é˜Ÿåˆ—
                        queue_list2 = root2.find('.//QueueList')
                        if queue_list2 is not None:
                            for q in queue_list2.findall('Queue'):
                                qid = q.findtext('QueueId')
                                qtype = q.findtext('QueueType') or q.findtext('Category')
                                qstate = q.findtext('State')
                                if qid and (qtype == 'AIProcess'):
                                    if qstate == 'Paused':
                                        self._activate_ai_queue(qid)
                                    logger.info(f"âœ… å¼€é€šåè·å¾— AIProcess é˜Ÿåˆ—: {qid}")
                                    return qid
                except Exception:
                    pass
            logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨é˜Ÿåˆ—ï¼Œä¸”è‡ªåŠ¨å¼€é€šå¤±è´¥æˆ–æœªç”Ÿæ•ˆã€‚è¯·åœ¨æ§åˆ¶å°å¯ç”¨â€˜AI å†…å®¹è¯†åˆ«â€™å¹¶åˆ›å»º/å¯ç”¨ AIProcess é˜Ÿåˆ—ï¼Œæˆ–æ›´æ¢åˆ°æ”¯æŒåœ°åŸŸçš„æ¡¶ã€‚")
            return ""

        except Exception as e:
            logger.error(f"ğŸ’¥ é˜Ÿåˆ—æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
            return ""

    async def _submit_ci_job(self, input_key: str, output_key: str, background_url: str = None) -> str:
        """æäº¤ä¸‡è±¡APIè§†é¢‘æŠ å›¾ä»»åŠ¡"""
        logger.info(f"ğŸ¬ æäº¤ä¸‡è±¡APIä»»åŠ¡: {input_key} -> {output_key}")
        
        # è·å–é˜Ÿåˆ—IDï¼ˆå¯èƒ½è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºä¸ä¼  QueueIdï¼‰
        queue_id = await self._get_queue_id()
        
        # ä¸‡è±¡APIçš„URL - ä½¿ç”¨æ­£ç¡®çš„åŸŸåæ ¼å¼
        ci_host = f"{self.bucket_name}.ci.{self.region}.myqcloud.com"
        url = f"https://{ci_host}/jobs"
        
        # æ„å»ºä»»åŠ¡é…ç½® - ä½¿ç”¨ Combination æ¨¡å¼å®ç°èƒŒæ™¯æ›¿æ¢
        segment_config = {
            "SegmentType": "HumanSeg",
            "BinaryThreshold": "0.1"  # é™ä½é˜ˆå€¼ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚
        }
        
        # æ ¹æ®æ˜¯å¦æä¾›èƒŒæ™¯å›¾ç‰‡é€‰æ‹©æ¨¡å¼
        if background_url:
            segment_config["Mode"] = "Combination"  # èƒŒæ™¯åˆæˆæ¨¡å¼
            segment_config["BackgroundLogoUrl"] = background_url  # æ ¹æ®å®˜æ–¹æ–‡æ¡£ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åç§°
            logger.info(f"ğŸ–¼ï¸ ä½¿ç”¨èƒŒæ™¯åˆæˆæ¨¡å¼ï¼ŒèƒŒæ™¯å›¾ç‰‡: {background_url}")
        else:
            segment_config["Mode"] = "Foreground"  # å‰æ™¯æ¨¡å¼
            logger.info("ğŸ­ ä½¿ç”¨å‰æ™¯æ¨¡å¼ï¼ˆæ— èƒŒæ™¯æ›¿æ¢ï¼‰")
        
        job_config = {
            "Tag": "SegmentVideoBody",
            "Input": {
                "Object": input_key
            },
            "Operation": {
                "SegmentVideoBody": segment_config,
                "Output": {
                    "Region": self.region,
                    "Bucket": self.bucket_name,
                    "Object": output_key,
                    "Format": "mp4"  # æ˜ç¡®æŒ‡å®šè¾“å‡ºæ ¼å¼
                }
            },
        }

        # ä»…å½“å‘ç° AIProcess é˜Ÿåˆ—æ—¶æ‰é™„åŠ  QueueId
        if queue_id:
            job_config["QueueId"] = queue_id
        
        # ç”Ÿæˆç­¾å
        authorization = self._generate_authorization("POST", "/jobs")
        headers = {
            'Authorization': authorization,
            'Host': ci_host,
            'Content-Type': 'application/xml',
            'Date': datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        }
        
        # è½¬æ¢ä¸ºXMLæ ¼å¼
        xml_data = self._dict_to_xml(job_config, "Request")
        logger.info(f"ğŸ“„ æäº¤çš„XMLæ•°æ®: {xml_data}")
        
        try:
            response = requests.post(url, data=xml_data, headers=headers, timeout=30, verify=True)
            logger.info(f"ğŸ“¡ ä¸‡è±¡APIå“åº”: {response.status_code}")
            logger.info(f"ğŸ“„ ä¸‡è±¡APIå“åº”å†…å®¹: {response.text}")
            
            if response.status_code == 200:
                # è§£æå“åº”è·å–JobId
                root = ET.fromstring(response.content)
                job_id = root.find('.//JobId').text if root.find('.//JobId') is not None else None
                
                if job_id:
                    logger.info(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸ: {job_id}")
                    return job_id
                else:
                    logger.error(f"âŒ æ— æ³•è·å–JobId: {response.text}")
                    raise Exception("æ— æ³•è·å–JobId")
            else:
                logger.error(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥: {response.status_code} - {response.text}")
                try:
                    err_root = ET.fromstring(response.text)
                    err_code = err_root.findtext('.//Code', default='Unknown')
                    err_msg = err_root.findtext('.//Message', default='')
                except Exception:
                    err_code, err_msg = 'Unknown', response.text

                if err_code == 'AIBucketUnBinded':
                    logger.warning("âš ï¸ æ£€æµ‹åˆ° AIBucketUnBindedï¼Œå°è¯•è‡ªåŠ¨å¼€é€š AI å†…å®¹è¯†åˆ«æœåŠ¡åé‡è¯•æäº¤ä»»åŠ¡")
                    if self._open_ai_bucket():
                        # ç­‰å¾…å‡ ç§’è®©é…ç½®ç”Ÿæ•ˆåé‡è¯•ä¸€æ¬¡
                        time.sleep(3)
                        retry_resp = requests.post(url, data=xml_data, headers=headers, timeout=30, verify=True)
                        logger.info(f"ğŸ“¡ é‡è¯•æäº¤å“åº”: {retry_resp.status_code}")
                        logger.info(f"ğŸ“„ é‡è¯•å“åº”å†…å®¹: {retry_resp.text}")
                        if retry_resp.status_code == 200:
                            root_retry = ET.fromstring(retry_resp.content)
                            job_id_retry = root_retry.findtext('.//JobId')
                            if job_id_retry:
                                logger.info(f"âœ… é‡è¯•æäº¤æˆåŠŸ: {job_id_retry}")
                                return job_id_retry
                    raise Exception("è¯¥å­˜å‚¨æ¡¶æœªå¼€é€šæˆ–æœªç»‘å®š æ•°æ®ä¸‡è±¡ AI å†…å®¹è¯†åˆ«ä¸è§†é¢‘äººåƒæŠ å›¾ï¼Œè¯·åœ¨æ§åˆ¶å°ä¸ºæ¡¶å¼€å¯â€˜æ•°æ®ä¸‡è±¡â€™ï¼Œå¯ç”¨â€˜AI å†…å®¹è¯†åˆ«â€™ï¼Œå¹¶åˆ›å»º/å¯ç”¨ç±»å‹ä¸º AIProcess çš„é˜Ÿåˆ—ï¼›è‹¥åœ°åŸŸä¸æ”¯æŒè¯¥èƒ½åŠ›ï¼Œè¯·åœ¨æ”¯æŒåœ°åŸŸæ–°å»ºæ¡¶å¹¶æ›´æ–°é…ç½®")

                raise Exception(f"ä»»åŠ¡æäº¤å¤±è´¥: {response.status_code}, Code={err_code}, Message={err_msg}")
                
        except Exception as e:
            logger.error(f"ğŸ’¥ ä¸‡è±¡APIå¼‚å¸¸: {str(e)}")
            raise Exception(f"ä¸‡è±¡APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def _dict_to_xml(self, data: dict, root_name: str = "Request") -> str:
        """å°†å­—å…¸è½¬æ¢ä¸ºXMLæ ¼å¼"""
        def build_xml(element, obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    sub_element = ET.SubElement(element, key)
                    build_xml(sub_element, value)
            elif isinstance(obj, list):
                for item in obj:
                    build_xml(element, item)
            else:
                element.text = str(obj)
        
        root = ET.Element(root_name)
        build_xml(root, data)
        return ET.tostring(root, encoding='unicode')
    
    async def _wait_for_job_completion(self, job_id: str, timeout: int = 300) -> bool:
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        logger.info(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ: {job_id}")
        
        ci_host = f"{self.bucket_name}.ci.{self.region}.myqcloud.com"
        url = f"https://{ci_host}/jobs/{job_id}"
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                authorization = self._generate_authorization("GET", f"/jobs/{job_id}")
                headers = {
                    'Authorization': authorization,
                    'Host': ci_host,
                    'Date': datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
                }
                
                response = requests.get(url, headers=headers, timeout=30, verify=True)
                
                if response.status_code == 200:
                    root = ET.fromstring(response.content)
                    state = root.find('.//State').text if root.find('.//State') is not None else "Unknown"
                    
                    logger.info(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {state}")
                    
                    if state == "Success":
                        logger.info(f"âœ… ä»»åŠ¡å®ŒæˆæˆåŠŸ: {job_id}")
                        return True
                    elif state == "Failed":
                        error_msg = root.find('.//Message').text if root.find('.//Message') is not None else "æœªçŸ¥é”™è¯¯"
                        logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}")
                        return False
                    elif state in ["Submitted", "Running"]:
                        logger.info(f"ğŸ”„ ä»»åŠ¡è¿›è¡Œä¸­: {state}")
                        await asyncio.sleep(10)  # ç­‰å¾…10ç§’åå†æ¬¡æ£€æŸ¥
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥çŠ¶æ€: {state}")
                        await asyncio.sleep(5)
                else:
                    logger.warning(f"âš ï¸ çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {response.status_code}")
                    await asyncio.sleep(5)
                    
            except Exception as e:
                logger.error(f"ğŸ’¥ çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
                await asyncio.sleep(5)
        
        logger.error(f"â° ä»»åŠ¡è¶…æ—¶: {job_id}")
        return False
    
    async def _process_with_ci_api(self, video_file_path: str, output_dir: str, background_url: str = None) -> str:
        """ä½¿ç”¨ä¸‡è±¡APIå¤„ç†è§†é¢‘"""
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‡è±¡APIå¤„ç†: {video_file_path}")
        
        # ç”Ÿæˆå”¯ä¸€çš„å¯¹è±¡é”®
        timestamp = int(time.time())
        input_key = f"input/video_{timestamp}.mp4"
        output_key = f"output/processed_{timestamp}.mp4"
        
        try:
            # æ­¥éª¤1: ä¸Šä¼ è§†é¢‘åˆ°COS
            logger.info("ğŸ“¤ æ­¥éª¤1: ä¸Šä¼ è§†é¢‘åˆ°COS")
            await self._upload_to_cos(video_file_path, input_key)
            
            # æ­¥éª¤2: æäº¤ä¸‡è±¡APIä»»åŠ¡
            logger.info("ğŸ¬ æ­¥éª¤2: æäº¤ä¸‡è±¡APIä»»åŠ¡")
            job_id = await self._submit_ci_job(input_key, output_key, background_url)
            
            # æ­¥éª¤3: ç­‰å¾…ä»»åŠ¡å®Œæˆ
            logger.info("â³ æ­¥éª¤3: ç­‰å¾…ä»»åŠ¡å®Œæˆ")
            success = await self._wait_for_job_completion(job_id)
            
            if not success:
                raise Exception("ä¸‡è±¡APIå¤„ç†å¤±è´¥")
            
            # æ­¥éª¤4: ä¸‹è½½å¤„ç†ç»“æœ
            logger.info("ğŸ“¥ æ­¥éª¤4: ä¸‹è½½å¤„ç†ç»“æœ")
            output_path = os.path.join(output_dir, f"ci_processed_{timestamp}.mp4")
            await self._download_from_cos(output_key, output_path)
            
            # æ­¥éª¤5: æ ‡å‡†åŒ–è§†é¢‘æ ¼å¼ä»¥ç¡®ä¿å­—å¹•å…¼å®¹æ€§
            logger.info("ğŸ”§ æ­¥éª¤5: æ ‡å‡†åŒ–è§†é¢‘æ ¼å¼")
            normalized_path = output_path.replace(".mp4", "_normalized.mp4")
            await self._normalize_video_for_subtitles(output_path, normalized_path)
            
            # æ›¿æ¢ä¸ºæ ‡å‡†åŒ–åçš„è§†é¢‘
            if os.path.exists(normalized_path) and os.path.getsize(normalized_path) > 0:
                import shutil
                shutil.move(normalized_path, output_path)
                logger.info(f"âœ… è§†é¢‘å·²æ ‡å‡†åŒ–: {output_path}")
            
            logger.info(f"âœ… ä¸‡è±¡APIå¤„ç†å®Œæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ä¸‡è±¡APIå¤„ç†å¤±è´¥: {str(e)}")
            raise e
    
    async def _normalize_video_for_subtitles(self, input_video: str, output_video: str) -> None:
        """æ ‡å‡†åŒ–è§†é¢‘æ ¼å¼ä»¥ç¡®ä¿å­—å¹•çƒ§å½•å…¼å®¹æ€§"""
        import subprocess
        import shutil
        
        ffmpeg = os.getenv("FFMPEG_PATH") or shutil.which("ffmpeg") or r"C:\ffmpeg\bin\ffmpeg.exe"
        
        # é‡æ–°ç¼–ç ä¸ºæ ‡å‡†H.264+AACï¼Œç¡®ä¿å…ƒæ•°æ®å®Œæ•´
        cmd = [
            ffmpeg,
            "-i", input_video,
            "-c:v", "libx264",
            "-preset", "fast",
            "-crf", "20",
            "-c:a", "aac",
            "-b:a", "128k",
            "-movflags", "+faststart",
            "-y", output_video
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                logger.info(f"è§†é¢‘æ ‡å‡†åŒ–æˆåŠŸ: {output_video}")
            else:
                logger.error(f"è§†é¢‘æ ‡å‡†åŒ–å¤±è´¥: {result.stderr}")
        except Exception as e:
            logger.error(f"è§†é¢‘æ ‡å‡†åŒ–å¼‚å¸¸: {str(e)}")
    
    async def upload_background_image(self, image_file_path: str) -> str:
        """
        ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡åˆ°COSå­˜å‚¨æ¡¶
        
        Args:
            image_file_path: èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: èƒŒæ™¯å›¾ç‰‡çš„COS URL
        """
        try:
            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡åˆ°COS: {image_file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_file_path):
                raise FileNotFoundError(f"èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_file_path}")
            
            # ç”Ÿæˆå”¯ä¸€çš„å¯¹è±¡é”®
            timestamp = int(time.time())
            file_ext = os.path.splitext(image_file_path)[1].lower()
            background_key = f"backgrounds/bg_{timestamp}{file_ext}"
            
            # ä¸Šä¼ åˆ°COS
            await self._upload_to_cos(image_file_path, background_key)
            
            # æ„å»ºCOS URL
            background_url = f"https://{self.bucket_name}.cos.{self.region}.myqcloud.com/{background_key}"
            
            logger.info(f"âœ… èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ æˆåŠŸ: {background_url}")
            return background_url
            
        except Exception as e:
            logger.error(f"ğŸ’¥ èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}")
            raise Exception(f"èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}")
    
    async def remove_background(self, video_file_path: str, output_dir: str, quality: str = "medium", background_url: str = None, background_file_path: str = None) -> Dict:
        """
        ä½¿ç”¨è…¾è®¯äº‘ä¸‡è±¡APIç§»é™¤è§†é¢‘èƒŒæ™¯
        
        Args:
            video_file_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            quality: å¤„ç†è´¨é‡ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
            background_url: èƒŒæ™¯å›¾ç‰‡URLï¼ˆç”¨äºCombinationæ¨¡å¼ï¼‰
            background_file_path: èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨ä¸Šä¼ åˆ°COSï¼‰
        """
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨è…¾è®¯äº‘ä¸‡è±¡APIå¤„ç†è§†é¢‘èƒŒæ™¯ç§»é™¤: {video_file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_file_path):
                raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file_path}")
            
            # æ£€æŸ¥é…ç½®
            if not self.bucket_name:
                raise Exception("æœªé…ç½®COSå­˜å‚¨æ¡¶")
            
            original_size = os.path.getsize(video_file_path)
            logger.info(f"åŸå§‹æ–‡ä»¶å¤§å°: {original_size / (1024*1024):.2f}MB")
            
            # å¤„ç†èƒŒæ™¯å›¾ç‰‡
            final_background_url = background_url
            if background_file_path and not background_url:
                # å¦‚æœæä¾›äº†èƒŒæ™¯æ–‡ä»¶è·¯å¾„ä½†æ²¡æœ‰URLï¼Œå…ˆä¸Šä¼ èƒŒæ™¯å›¾ç‰‡
                logger.info("ğŸ–¼ï¸ æ£€æµ‹åˆ°èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶ï¼Œå¼€å§‹ä¸Šä¼ åˆ°COS")
                final_background_url = await self.upload_background_image(background_file_path)
            
            # ä½¿ç”¨ä¸‡è±¡APIå¤„ç†è§†é¢‘
            output_path = await self._process_with_ci_api(video_file_path, output_dir, final_background_url)
            
            processed_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0
            processing_time = time.time() - start_time
            
            logger.info(f"è…¾è®¯äº‘ä¸‡è±¡èƒŒæ™¯ç§»é™¤å®Œæˆ: {output_path}")
            return {
                "success": True,
                "output_path": output_path,
                "original_size": original_size,
                "processed_size": processed_size,
                "processing_time": processing_time,
                "service": "tencent_ci",
                "cost_estimate": "æŒ‰ä¸‡è±¡APIè®¡è´¹",
                "background_mode": "Combination" if final_background_url else "Foreground",
                "background_url": final_background_url
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"è…¾è®¯äº‘ä¸‡è±¡èƒŒæ™¯ç§»é™¤å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "output_path": "",
                "original_size": 0,
                "processed_size": 0,
                "processing_time": processing_time,
                "service": "failed",
                "error": str(e)
            }